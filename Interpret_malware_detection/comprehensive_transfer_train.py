from __future__ import print_function
from __future__ import division
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
from torch.utils.data import DataLoader
from torchvision import datasets, models, transforms
import sys
from process_models.transfer import *
from sklearn.model_selection import StratifiedKFold
from process_models.confusion_matrix import plot_conf_matrix,detection_class_report_curve
from process_models.view import *
from k_fold.k_fold_split import *

def train_model(scheduler,model_name,model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):
    since = time.time()
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0
    train_acc_history=[]
    train_loss_history=[]
    val_acc_history=[]
    val_loss_history=[]

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['train', 'test']:
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            running_corrects = 0
            for inputs, labels in tqdm(dataloaders[phase]):
                inputs = inputs.to(device)
                labels = labels.to(device)
                optimizer.zero_grad()
                with torch.set_grad_enabled(phase == 'train'):
                    if is_inception and phase == 'train':
                        outputs, aux_outputs = model(inputs)
                        loss1 = criterion(outputs, labels)
                        loss2 = criterion(aux_outputs, labels)
                        loss = loss1 + 0.4*loss2
                    else:
                        outputs = model(inputs)
                        loss = criterion(outputs, labels)

                    _, preds = torch.max(outputs, 1)

                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # statistics
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
            # if phase=='train':
            #     scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase].dataset)
            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)

            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))

            # deep copy the model
            # if phase=='test':
                # scheduler.step(epoch_acc)
            if phase=='train':
                scheduler.step()
            if phase == 'test' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())
            if phase == 'train':
                train_acc_history.append(epoch_acc)
                train_loss_history.append(epoch_loss)
            if phase == 'test':
                val_acc_history.append(epoch_acc)
                val_loss_history.append(epoch_loss)
    model.load_state_dict(best_model_wts)
    visualize_outcome(train_acc_history,train_loss_history,val_acc_history,val_loss_history,0,model_name)
    time_elapsed = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
    print('Best test Acc: {:4f}'.format(best_acc))
    return model

def k_fold_corss_validation_train_model(batch_size,scheduler,model_name,k_fold,model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):
    since = time.time()
    best_val_history=[]
    seed = 7
    np.random.seed(seed)
    kfold=StratifiedKFold(n_splits=k_fold,shuffle=True,random_state=seed)
    data,label=get_data(dataloaders)#更改一下，因为修改后的get——data有两个参数
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0
    i = 0
    for train, val in kfold.split(data, label):
        print('#the {}th fold'.format(i))
        train_set = torch.utils.data.dataset.Subset(data, train)
        train_label=torch.utils.data.dataset.Subset(label,train)
        val_set = torch.utils.data.dataset.Subset(data, val)
        val_label=torch.utils.data.dataset.Subset(label, val)
        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,
                                                   shuffle=False, num_workers=4)
        train_label_loader=torch.utils.data.DataLoader(train_label, batch_size=batch_size,
                                                   shuffle=False, num_workers=4)
        val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,
                                                 shuffle=False, num_workers=4)
        val_label_loader = torch.utils.data.DataLoader(val_label, batch_size=batch_size,
                                             shuffle=False, num_workers=4)
        dataloaders_data={'train':train_loader,'val':val_loader}
        dataloaders_label={'train':train_label_loader,'val':val_label_loader}
        val_acc_history = []
        train_acc_history=[]
        val_loss_history=[]
        train_loss_history=[]
        best_epoch_acc = 0.0
        for epoch in range(num_epochs):
            print('Epoch {}/{}'.format(epoch, num_epochs - 1))
            print('-' * 10)

            # Each epoch has a training and validation phase
            for phase in ['train', 'val']:
                if phase == 'train':
                    model.train()  # Set model to training mode
                else:
                    model.eval()   # Set model to evaluate mode
                running_loss = 0.0
                running_corrects = 0
                for inputs, labels in tqdm(zip(dataloaders_data[phase],dataloaders_label[phase])):
                    inputs = inputs.to(device)
                    labels = labels.to(device)
                    optimizer.zero_grad()
                    with torch.set_grad_enabled(phase == 'train'):
                        if is_inception and phase == 'train':
                            outputs, aux_outputs = model(inputs)
                            loss1 = criterion(outputs, labels)
                            loss2 = criterion(aux_outputs, labels)
                            loss = loss1 + 0.4*loss2
                        else:
                            outputs = model(inputs)
                            loss = criterion(outputs, labels)

                        _, preds = torch.max(outputs, 1)

                        # backward + optimize only if in training phase
                        if phase == 'train':
                            loss.backward()
                            optimizer.step()

                    # statistics
                    running_loss += loss.item() * inputs.size(0)
                    running_corrects += torch.sum(preds == labels.data)
                # if phase=='train':
                #     scheduler.step()
                epoch_loss = running_loss / len(dataloaders_data[phase].dataset)
                epoch_acc = running_corrects.double() / len(dataloaders_data[phase].dataset)

                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))

                # deep copy the model
                # if phase=='val':
                #     scheduler.step(epoch_acc)
                if phase=='train':
                    scheduler.step()
                if phase=='val' and epoch_acc>best_epoch_acc:
                    best_epoch_acc=epoch_acc
                if phase == 'val' and epoch_acc > best_acc:
                    best_acc = epoch_acc
                    best_model_wts = copy.deepcopy(model.state_dict())
                if phase == 'train':
                    train_acc_history.append(epoch_acc)
                    train_loss_history.append(epoch_loss)
                if phase == 'val':
                    val_acc_history.append(epoch_acc)
                    val_loss_history.append(epoch_loss)
        model.load_state_dict(best_model_wts)
        visualize_outcome(train_acc_history,train_loss_history,val_acc_history,val_loss_history,i,model_name)
        i+=1
        time_elapsed = time.time() - since
        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
        print('Best val Acc: {:4f}'.format(best_acc))
        best_val_history.append(best_epoch_acc)
        del train_set,val_set,train_loader,val_loader,train_label,val_label,train_label_loader,val_label_loader
        gc.collect()
        if i==2 or best_epoch_acc>=0.98:#when validation attains 5-fold, then we stop due to experience
            break
        else:
            pass

    # load best model weights
    model.load_state_dict(best_model_wts)
    # Show results
    for n in range(len(best_val_history)):  # show results for each fold
        print("No.", n, "Fold test Accuracy of the model on the test images: {} ".format(best_val_history[n]))
    # print("Std in 10-Fold is", np.std(best_val_history))
    # print("Med in 10-Fold is", np.median(best_val_history))
    # print("Average accuracy in 10-Fold is", np.average(best_val_history))
    return model, best_val_history

def set_parameter_requires_grad(model, feature_extracting):
    if feature_extracting:
        for param in model.parameters():
            param.requires_grad = False

def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True,input_size_used=224):
    # Initialize these variables which will be set in this if statement. Each of these
    #   variables is model specific.
    model_ft = None
    input_size = 0
    if model_name=='resnext50':
        "resnext50"
        model_ft=models.resnext50_32x4d(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs, num_classes)
        input_size = input_size_used
    elif model_name=='resnext101':
        "resnext101"
        model_ft = models.resnext101_32x8d(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs, num_classes)
        input_size = input_size_used
    elif model_name == 'resnet50':
        """ Resnet50
        """
        model_ft = models.resnet50(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs, num_classes)
        input_size = input_size_used
    elif model_name=='resnet101':
        'resnet101'
        model_ft = models.resnet101(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs, num_classes)
        input_size = input_size_used
    elif model_name=='resnet152':
        'resnet152'
        model_ft = models.resnet152(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs, num_classes)
        input_size = input_size_used
    elif model_name=='resnet18':
        'resnet18'
        model_ft = models.resnet18(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs, num_classes)
        input_size = input_size_used
    elif model_name == 'alexnet':
        """ Alexnet
        """
        model_ft = models.alexnet(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier[6].in_features
        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)
        input_size = input_size_used

    elif model_name == 'vgg11_bn':
        """ VGG11_bn
        """
        model_ft = models.vgg11_bn(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier[6].in_features
        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)
        input_size = input_size_used
    elif model_name=='vgg16':
        'vgg16'
        model_ft=models.vgg16(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier[6].in_features
        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)
        input_size = input_size_used
    elif model_name=='vgg19':
        'vgg19'
        model_ft=models.vgg19(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier[6].in_features
        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)
        input_size = input_size_used
    elif model_name == 'squeezenet':
        """ Squeezenet
        """
        model_ft = models.squeezenet1_0(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))
        model_ft.num_classes = num_classes
        input_size = input_size_used
    elif model_name == 'densenet121':
        """ Densenet
        """
        model_ft = models.densenet121(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier.in_features
        model_ft.classifier = nn.Linear(num_ftrs, num_classes)
        input_size = input_size_used

    elif model_name == 'inception_v3':
        """ Inception v3
        Be careful, expects (299,299) sized images and has auxiliary output
        """
        model_ft = models.inception_v3(pretrained=use_pretrained)
        model_ft.aux_logits = False
        set_parameter_requires_grad(model_ft, feature_extract)
        # Handle the auxilary net
        num_ftrs = model_ft.AuxLogits.fc.in_features
        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)
        # Handle the primary net
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs,num_classes)
        input_size = 299
    elif model_name=='IIMD'or model_name=='RRV_complete':
        'IIMD'
        # c1=torch.load(r'C:\Users\lin\Desktop\gradduate_design\model\malimg_model_tl\resnet50_tl_malimg.pt')
        # c2=torch.load(r'C:\Users\lin\Desktop\gradduate_design\model\malimg_model_tl\squeezenet_tl_malimg.pt')
        # c3=torch.load(r'C:\Users\lin\Desktop\gradduate_design\model\malimg_model_tl\densenet121_tl_malimg.pt')
        # c5=torch.load(r'C:\Users\lin\Desktop\gradduate_design\model\malimg_model_tl\resnext50_tl_malimg.pt')
        # c6=torch.load(r'C:\Users\lin\Desktop\gradduate_design\model\malimg_model_tl\resnet18_tl_malimg.pt')
        model_ft=IIMD()
        input_size=input_size_used
    else:
        print("Invalid model name, exiting...")
        sys.exit()

    return model_ft, input_size

if __name__=='__main__':
    # data_dir = r'C:\Users\lin\Desktop\gradduate_design\malware_grayscale_interpret\IoT_malware_grayscale_images'
    data_dir=r'C:\Users\lin\Desktop\gradduate_design\malware_grayscale_interpret\malware_greyscale_families'
    # Models to choose from [resnet50, alexnet, vgg11_bn,vgg16, squeezenet, densenet121, inception v3]
    # model_choice = ['resnet50','inception_v3','densenet121','IIMD']
    # model_choice=['IIMD']
    # model_choice=['resnet18','resnet50','vgg11_bn','vgg16','squeezenet','densenet121',
    #               'inception v3','alexnet','IIMD']
    # model_choice=['resnext50','resnext101']
    model_choice=['RRV_complete']
    # Number of classes in the dataset
    num_classes = 25

    # Batch size for training (change depending on how much memory you have)
    batch_size = 2

    # Number of epochs to train for
    num_epochs = 20

    #k-fold
    k_fold = 10

    # Flag for feature extracting. When False, we finetune the whole model,
    #   when True we only update the reshaped layer params

    button='train'# ['train', 'interpret'，‘test'，‘DTD_train]

    ###################################
    k_fold_accuracy=[]
    if button=='train':
        for index,model_name in enumerate(model_choice):
            if model_name=='resnext50' or model_name=='resnext101':
                feature_extract = False
            else:
                feature_extract = True
            # Initialize the model for this run
            print('transfer train {}'.format(model_name))
            model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True,input_size_used=224)

            # Print the model we just instantiated
            data_transforms = {
                'train': transforms.Compose([
                    transforms.Resize(input_size),
                    # transforms.RandomResizedCrop(input_size),#data preprocessing need proved
                    # transforms.RandomHorizontalFlip(),
                    transforms.CenterCrop(input_size),
                    transforms.ToTensor(),
                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                ]),
                'test': transforms.Compose([
                    transforms.Resize(input_size),
                    transforms.CenterCrop(input_size),
                    transforms.ToTensor(),
                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                ]),
            }

            print("Initializing Datasets and Dataloaders...")

            # Create training and validation datasets
            image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'test']}
            # Create training and validation dataloaders
            dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False, num_workers=4) for x in ['train', 'test']}

            # Detect if we have a GPU available
            device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
            print(device)
            model_ft = model_ft.to(device)

            # Gather the parameters to be optimized/updated in this run. If we are
            #  finetuning we will be updating all parameters. However, if we are
            #  doing feature extract method, we will only update the parameters
            #  that we have just initialized, i.e. the parameters with requires_grad
            #  is True.
            if model_name=='RRV_complete':
                class_names = image_datasets['train'].classes
                path=r'C:\Users\lin\Desktop\gradduate_design\model\malimg_model_tl\RRV_complete.pt'
                # model_ft,best_val_history=IIMD_train(model_ft,path,dataloaders_dict,device,10,batch_size,model_name)
                model_ft=torch.load(path)
                # k_fold_accuracy.append(best_val_history)
                # visualize_outcome_inOneModel(best_val_history,model_name)
                RRV_test(model_ft, dataloaders_dict, device, class_names,model_name)  # 如果要测试，需要把dataloader改为有序取出
                # plot_conf_matrix(dataloaders_dict,model_ft,class_names,device,model_name)
            elif model_name=='IIMD':
                path=r'C:\Users\lin\Desktop\gradduate_design\model\IOT_model_tl\IIMD_IOT.pt'
                # path=r'C:\Users\lin\Desktop\gradduate_design\model\malimg_model_tl\IIMD.pt'
                # iimd,best_val_history=IIMD_train(model_ft,path,dataloaders_dict,device,k_fold,batch_size,model_name)
                # iimd=torch.load(path)
                iimd=torch.load(path)
                class_names = image_datasets['test'].classes
                transfer_test(iimd,dataloaders_dict,device,class_names)#如果要测试，需要把dataloader改为有序取出
                k_fold_accuracy.append(best_val_history)
                visualize_outcome_inOneModel(best_val_history, model_name)  # 绘制一个模型的k-fold曲线
            else:
                params_to_update = model_ft.parameters()
                print("Params to learn:")
                if feature_extract:
                    params_to_update = []
                    for name,param in model_ft.named_parameters():
                        if param.requires_grad == True:
                            params_to_update.append(param)
                            print("\t",name)
                else:
                    for name,param in model_ft.named_parameters():
                        if param.requires_grad == True:
                            print("\t",name)

                # Observe that all parameters are being optimized
                optimizer_ft = optim.SGD(params_to_update, lr=0.01, momentum=0.9)
                # optimizer_ft=optim.Adam(params_to_update,lr=0.01,betas=(0.9,0.999),eps=1e-08,weight_decay=0,amsgrad=False)
                # Setup the loss fxn
                criterion = nn.CrossEntropyLoss()
                #modify the lr step
                # exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)
                # exp_lr_scheduler=lr_scheduler.ReduceLROnPlateau(optimizer_ft, mode='min', factor=0.1, patience=3,
         # verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)
                exp_lr_scheduler=lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=10, eta_min=0, last_epoch=-1)
                # Train and evaluate
                model_ft, best_val_history = k_fold_corss_validation_train_model(batch_size,exp_lr_scheduler,model_name,k_fold,model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name=="inception"))
                # model=train_model(exp_lr_scheduler,model_name,model_ft,dataloaders_dict,criterion,optimizer_ft,40,is_inception=(model_name=="inception"))
                torch.save(model_ft,r'C:\Users\lin\Desktop\gradduate_design\model\malimg_model_tl\{}_tl_malimg.pt'.format(model_name))
                k_fold_accuracy.append(best_val_history)
                visualize_outcome_inOneModel(best_val_history,model_name)#绘制一个模型的k-fold曲线
                #Detection
                # model_ft=torch.load(r'C:\Users\lin\Desktop\gradduate_design\model\resnet50_mal_iot_2.pt')
                class_names = image_datasets['test'].classes
                plot_conf_matrix(dataloaders_dict, model_ft, class_names, device,model_name)#绘制一个模型的侦测混淆矩阵和曲线
                del input_size,data_transforms,image_datasets,dataloaders_dict,device,model_ft,params_to_update,optimizer_ft,criterion
                gc.collect()
        visualize_k_fold_outcome(k_fold_accuracy, model_choice)  # 绘制所有模型的k-fold曲线
    elif button=='plot':
        input_size=224
        data_transforms = {
            'train': transforms.Compose([
                transforms.Resize(input_size),
                # transforms.RandomResizedCrop(input_size),#data preprocessing need proved
                # transforms.RandomHorizontalFlip(),
                transforms.CenterCrop(input_size),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
            'test': transforms.Compose([
                transforms.Resize(input_size),
                transforms.CenterCrop(input_size),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
        }

        print("Initializing Datasets and Dataloaders...")

        # Create training and validation datasets
        image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in
                          ['train', 'test']}
        # Create training and validation dataloaders
        dataloaders_dict = {
            x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False, num_workers=4) for x
            in ['train', 'test']}
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        class_names = image_datasets['test'].classes
        plot_detect_malimg(model_choice,device,dataloaders_dict,class_names)
    elif button=='interpret':
        print('interpret')
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        input_size = 224
        data_transforms = {
            'train': transforms.Compose([
                transforms.Resize(input_size),
                # transforms.RandomResizedCrop(input_size),#data preprocessing need proved
                # transforms.RandomHorizontalFlip(),
                transforms.CenterCrop(input_size),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
            'test': transforms.Compose([
                transforms.Resize(input_size),
                transforms.CenterCrop(input_size),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
        }

        # print("Initializing Datasets and Dataloaders...")
        image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in
                          ['train', 'test']}
        # Create training and validation dataloaders
        dataloaders_dict = {
            x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False, num_workers=4) for x
            in ['train', 'test']}
        class_names = image_datasets['test'].classes
        path = r'C:\Users\lin\Desktop\gradduate_design\model\malimg_model_tl\RRV_complete.pt'
        path_2=r'C:\Users\lin\Desktop\gradduate_design\model\malimg_model_tl\resnet50_tl_malimg.pt'
        model_ft = torch.load(path)
        print(model_ft)
        # model_ft=resnet50_convert_format(model_ft)
        model_ft=model_ft.to(device)
        path_right=r'C:\Users\lin\Desktop\gradduate_design\Interpret_malware_detection\results\DTD_results\malimg_DTD\RRV_right'
        path_wrong=r'C:\Users\lin\Desktop\gradduate_design\Interpret_malware_detection\results\DTD_results\malimg_DTD\RRV_wrong'
        # DTD_interpret(model_ft, 5000, 'resnet', dataloaders_dict, device, class_names, path_right, path_wrong)
        DTD_ensemble_interpret(model_ft,5000,dataloaders_dict,device,class_names,path_right,path_wrong,batch_size)
    elif button=='DTD_train':
        print('begin to use DTD to enhance training robustness...')
        model=torch.load(r'C:\Users\lin\Desktop\gradduate_design\model\malimg_model_tl\RRV_complete.pt')
        path=r'C:\Users\lin\Desktop\gradduate_design\model\malimg_model_tl\RRV_complete_DTD_finetune_firstlayer.pt'
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        print('fine-tune RRV')
        model=RRV_fine_tune_first_layer(model)
        model = model.to(device)
        print('success')
        input_size = 224
        data_transforms = {
            'train': transforms.Compose([
                transforms.Resize(input_size),
                transforms.CenterCrop(input_size),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
            'test': transforms.Compose([
                transforms.Resize(input_size),
                transforms.CenterCrop(input_size),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
        }

        image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in
                          ['train', 'test']}
        dataloaders_dict = {
            x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False, num_workers=4) for x
            in ['train', 'test']}
        class_names = image_datasets['test'].classes
        # DTD_train_data,DTD_train_label,DTD_test_data,DTD_test_label=DTD_prepare_dropout(dataloaders_dict,model,5000,class_names,device)
        # torch.save(DTD_train_data , r'C:\Users\lin\Desktop\gradduate_design\model\dataloader\RRV\DTD\train_data.pt')
        # torch.save(DTD_train_label , r'C:\Users\lin\Desktop\gradduate_design\model\dataloader\RRV\DTD\train_label.pt')
        # torch.save(DTD_test_data , r'C:\Users\lin\Desktop\gradduate_design\model\dataloader\RRV\DTD\test_data.pt')
        # torch.save(DTD_test_label , r'C:\Users\lin\Desktop\gradduate_design\model\dataloader\RRV\DTD\test_label.pt')
        DTD_train_data=torch.load(r'C:\Users\lin\Desktop\gradduate_design\model\dataloader\RRV\DTD\train_data.pt')
        DTD_train_label=torch.load(r'C:\Users\lin\Desktop\gradduate_design\model\dataloader\RRV\DTD\train_label.pt')
        DTD_test_data=torch.load(r'C:\Users\lin\Desktop\gradduate_design\model\dataloader\RRV\DTD\test_data.pt')
        DTD_test_label=torch.load(r'C:\Users\lin\Desktop\gradduate_design\model\dataloader\RRV\DTD\test_label.pt')
        print('saved')
        dataloader_dict, labelloader_dict = DTD_dataloader(DTD_train_data, DTD_train_label, DTD_test_data,
                                                           DTD_test_label,batch_size)
        #根据DTD的可解释映射定性抑制输入神经元，训练RRV基分类器输入卷积层和二级全连接层，10-折交叉验证学习
        model,best_acc=RRV_DTD_train(model,path,dataloader_dict,labelloader_dict,device,10,batch_size,model_choice[0],class_names)
        RRV_test(model,dataloaders_dict,labelloader_dict,device,class_names,model_choice[0])#测试训练好的RRV_DTD的效果
        visualize_outcome_inOneModel(best_acc, model_choice[0])#显示k-折交叉验证训练过程曲线
    elif button=='test':
        model = torch.load(r'C:\Users\lin\Desktop\gradduate_design\model\malimg_model_tl\RRV_complete.pt')
        RRV_fine_tune_first_layer(model)
        print(model)